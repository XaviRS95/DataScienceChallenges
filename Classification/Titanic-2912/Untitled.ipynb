{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf1a6b25-95cd-45eb-a2b5-2b61899d1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fcc757a-2526-4136-bbbb-4f1308b6a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprocessing(data):\n",
    "\n",
    "    data.drop('Name', axis = 1, inplace = True)\n",
    "    \n",
    "    data.drop(['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], axis = 1, inplace = True)\n",
    "    \n",
    "    data['Age'].fillna(int(data['Age'].mean(skipna = True)), inplace = True)\n",
    "    \n",
    "    data['Group'] = data['PassengerId'].apply(lambda x: int(x.split('_')[1]))\n",
    "    data.drop('PassengerId', axis = 1, inplace = True)\n",
    "    \n",
    "    data[['Deck', 'Num', 'Side']] = data['Cabin'].str.split('/', expand = True)\n",
    "    data.drop('Num', axis = 1, inplace = True)\n",
    "    data.drop('Cabin', axis = 1, inplace = True)\n",
    "    data['Deck'].fillna('Missing', inplace = True)\n",
    "    data['Side'].fillna('Missing', inplace = True)\n",
    "\n",
    "    data['Destination'].fillna('Missing', inplace = True)\n",
    "    data['CryoSleep'] = train_data['CryoSleep'].apply(lambda x: 1 if x else 0)\n",
    "    data['VIP'] = train_data['CryoSleep'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    data = pd.get_dummies(data, dtype = int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e1b105c-ce0e-4a34-849b-26f6d5ed6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "train_IDs = train_data['PassengerId']\n",
    "target_train = train_data['Transported']\n",
    "train_data.drop('Transported', axis = 1, inplace = True)\n",
    "clean_train_data = dataprocessing(train_data)\n",
    "\n",
    "clean_train_data.to_csv('clean_train_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e4de1a-997d-45c3-aced-0e76c74ad370",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_train_data, target_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6cde900-6b3a-4253-b9f6-fb0f40e93209",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'rf': make_pipeline(MinMaxScaler(), RandomForestClassifier(random_state=1234)),\n",
    "    'gb': make_pipeline(MinMaxScaler(), GradientBoostingClassifier(random_state=1234))\n",
    "}\n",
    "\n",
    "grid = {\n",
    "    'rf': {\n",
    "        'randomforestclassifier__n_estimators':[100,200,300]\n",
    "    },\n",
    "    'gb':{\n",
    "        'gradientboostingclassifier__n_estimators':[100,200,300]\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33bc72-7669-4466-8c21-853af76ef325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the rf model.\n"
     ]
    }
   ],
   "source": [
    "# Create a blank dictionary to hold the models \n",
    "fit_models = {}\n",
    "# Loop through all the algos \n",
    "for algo, pipeline in pipelines.items():\n",
    "  print(f'Training the {algo} model.')\n",
    "  # Create new Grid Search CV Cclass \n",
    "  model = GridSearchCV(pipeline, grid[algo], n_jobs=-1, cv=10)\n",
    "  # Train the model \n",
    "  model.fit(X_train, y_train)\n",
    "  # Store results inside of the dictionary\n",
    "  fit_models[algo] = model \n",
    "\n",
    "\n",
    "# Evaluate the performance of the model \n",
    "for algo, model in fit_models.items(): \n",
    "  yhat = model.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test, yhat)\n",
    "  precision = precision_score(y_test, yhat)\n",
    "  recall = recall_score(y_test, yhat)\n",
    "  print(f'Metrics for {algo}: accuracy- {accuracy}, recall- {recall}, precision- {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43355384-601b-47aa-95ff-fd7698d26dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "test_IDs = test_data['PassengerId']\n",
    "clean_test_data = dataprocessing(test_data)\n",
    "\n",
    "y_results = fit_models['gb'].predict(clean_test_data)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'PassengerId':test_IDs,\n",
    "    'Transported':y_results\n",
    "}).to_csv('results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffae64-b209-430b-ab24-e3c8dbee6ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
